{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from jaxtyping import Int, Array\n",
    "from typing import List\n",
    "from jax.nn import silu\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap\n",
    "import jax\n",
    "import optax\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  stack=Sequential(\n",
       "    layers=(\n",
       "      Linear(\n",
       "        weight=f32[128,4],\n",
       "        bias=f32[128],\n",
       "        in_features=4,\n",
       "        out_features=128,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      RMSNorm(\n",
       "        shape=(128,),\n",
       "        eps=1e-05,\n",
       "        use_weight=True,\n",
       "        use_bias=True,\n",
       "        weight=f32[128],\n",
       "        bias=f32[128]\n",
       "      ),\n",
       "      Linear(\n",
       "        weight=f32[128,128],\n",
       "        bias=f32[128],\n",
       "        in_features=128,\n",
       "        out_features=128,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      RMSNorm(\n",
       "        shape=(128,),\n",
       "        eps=1e-05,\n",
       "        use_weight=True,\n",
       "        use_bias=True,\n",
       "        weight=f32[128],\n",
       "        bias=f32[128]\n",
       "      ),\n",
       "      Linear(\n",
       "        weight=f32[2,128],\n",
       "        bias=f32[2],\n",
       "        in_features=128,\n",
       "        out_features=2,\n",
       "        use_bias=True\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(eqx.Module):\n",
    "    stack: List\n",
    "\n",
    "    def __init__(\n",
    "        self, rng, in_features: int, out_features: int, hidden_size: int, n_layers: int\n",
    "    ):\n",
    "        keys = jax.random.split(rng, n_layers)\n",
    "        first_layer = eqx.nn.Linear(\n",
    "            key=keys[0], in_features=in_features, out_features=hidden_size\n",
    "        )\n",
    "        last_layer = eqx.nn.Linear(\n",
    "            key=keys[-1], in_features=hidden_size, out_features=out_features\n",
    "        )\n",
    "        self.stack = eqx.nn.Sequential(\n",
    "            [first_layer, eqx.nn.RMSNorm(hidden_size)]\n",
    "            + list(\n",
    "                *zip(\n",
    "                    [\n",
    "                        eqx.nn.Linear(\n",
    "                            key=keys[i],\n",
    "                            in_features=hidden_size,\n",
    "                            out_features=hidden_size,\n",
    "                        )\n",
    "                        for i in range(1, n_layers - 1)\n",
    "                    ],\n",
    "                    [eqx.nn.RMSNorm(hidden_size) for _ in range(1, n_layers - 1)],\n",
    "                )\n",
    "            )\n",
    "            + [last_layer]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for i in range(0, len(self.stack) - 1, 2):\n",
    "            x = silu(self.stack[i + 1](self.stack[i](x)))\n",
    "        return self.stack[-1](x)\n",
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "mlp = MLP(rng, 4, 2, 128, 3)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.39269477, -0.11479907],\n",
       "       [-0.0050479 ,  0.41385213],\n",
       "       [ 0.27943578, -0.02031695],\n",
       "       [-0.0377685 , -0.21515   ],\n",
       "       [-0.11294541,  0.15727353],\n",
       "       [-0.38071093,  0.14485542],\n",
       "       [ 0.31257132,  0.323749  ],\n",
       "       [ 0.3690706 , -0.47695047]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmapped = jax.jit(jax.vmap(mlp))\n",
    "input = jax.random.normal(rng, (8, 4))\n",
    "output = jax.random.normal(rng, (8, 2))\n",
    "vmapped(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.02830462,  0.46713185],\n",
       "       [ 0.29570296,  0.15354592],\n",
       "       [-0.12403282,  0.21692315],\n",
       "       [-1.4408789 ,  0.7558599 ],\n",
       "       [ 0.52140963,  0.9101704 ],\n",
       "       [-0.3844966 ,  1.1398233 ],\n",
       "       [ 1.4457862 ,  1.0809066 ],\n",
       "       [-0.05629321,  0.9095945 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def cross_entropy_loss(model, x, y):\n",
    "    return jnp.linalg.norm(vmap(model)(x) - y)\n",
    "\n",
    "\n",
    "optim = optax.adamw(1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, grads = jax.value_and_grad(cross_entropy_loss)(mlp, input, output)\n",
    "opt_state = optim.init(mlp)\n",
    "updates, opt_state = optim.update(grads, opt_state, eqx.filter(mlp, eqx.is_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  stack=Sequential(\n",
       "    layers=(\n",
       "      Linear(\n",
       "        weight=f32[128,4],\n",
       "        bias=f32[128],\n",
       "        in_features=4,\n",
       "        out_features=128,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      RMSNorm(\n",
       "        shape=(128,),\n",
       "        eps=1e-05,\n",
       "        use_weight=True,\n",
       "        use_bias=True,\n",
       "        weight=f32[128],\n",
       "        bias=f32[128]\n",
       "      ),\n",
       "      Linear(\n",
       "        weight=f32[128,128],\n",
       "        bias=f32[128],\n",
       "        in_features=128,\n",
       "        out_features=128,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      RMSNorm(\n",
       "        shape=(128,),\n",
       "        eps=1e-05,\n",
       "        use_weight=True,\n",
       "        use_bias=True,\n",
       "        weight=f32[128],\n",
       "        bias=f32[128]\n",
       "      ),\n",
       "      Linear(\n",
       "        weight=f32[2,128],\n",
       "        bias=f32[2],\n",
       "        in_features=128,\n",
       "        out_features=2,\n",
       "        use_bias=True\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.39128035, -0.11116907],\n",
       "       [-0.00265342,  0.41814655],\n",
       "       [ 0.2782694 , -0.01608188],\n",
       "       [-0.039456  , -0.21209644],\n",
       "       [-0.11179534,  0.16160005],\n",
       "       [-0.37851924,  0.14782496],\n",
       "       [ 0.31495827,  0.32719198],\n",
       "       [ 0.36712554, -0.4736853 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_ = eqx.apply_updates(mlp, updates)\n",
    "vmap(mlp_)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ScaleByAdamState(count=Array(1, dtype=int32), mu=MLP(\n",
       "   stack=Sequential(\n",
       "     layers=(\n",
       "       Linear(\n",
       "         weight=f32[128,4],\n",
       "         bias=f32[128],\n",
       "         in_features=4,\n",
       "         out_features=128,\n",
       "         use_bias=True\n",
       "       ),\n",
       "       RMSNorm(\n",
       "         shape=(128,),\n",
       "         eps=1e-05,\n",
       "         use_weight=True,\n",
       "         use_bias=True,\n",
       "         weight=f32[128],\n",
       "         bias=f32[128]\n",
       "       ),\n",
       "       Linear(\n",
       "         weight=f32[128,128],\n",
       "         bias=f32[128],\n",
       "         in_features=128,\n",
       "         out_features=128,\n",
       "         use_bias=True\n",
       "       ),\n",
       "       RMSNorm(\n",
       "         shape=(128,),\n",
       "         eps=1e-05,\n",
       "         use_weight=True,\n",
       "         use_bias=True,\n",
       "         weight=f32[128],\n",
       "         bias=f32[128]\n",
       "       ),\n",
       "       Linear(\n",
       "         weight=f32[2,128],\n",
       "         bias=f32[2],\n",
       "         in_features=128,\n",
       "         out_features=2,\n",
       "         use_bias=True\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ), nu=MLP(\n",
       "   stack=Sequential(\n",
       "     layers=(\n",
       "       Linear(\n",
       "         weight=f32[128,4],\n",
       "         bias=f32[128],\n",
       "         in_features=4,\n",
       "         out_features=128,\n",
       "         use_bias=True\n",
       "       ),\n",
       "       RMSNorm(\n",
       "         shape=(128,),\n",
       "         eps=1e-05,\n",
       "         use_weight=True,\n",
       "         use_bias=True,\n",
       "         weight=f32[128],\n",
       "         bias=f32[128]\n",
       "       ),\n",
       "       Linear(\n",
       "         weight=f32[128,128],\n",
       "         bias=f32[128],\n",
       "         in_features=128,\n",
       "         out_features=128,\n",
       "         use_bias=True\n",
       "       ),\n",
       "       RMSNorm(\n",
       "         shape=(128,),\n",
       "         eps=1e-05,\n",
       "         use_weight=True,\n",
       "         use_bias=True,\n",
       "         weight=f32[128],\n",
       "         bias=f32[128]\n",
       "       ),\n",
       "       Linear(\n",
       "         weight=f32[2,128],\n",
       "         bias=f32[2],\n",
       "         in_features=128,\n",
       "         out_features=2,\n",
       "         use_bias=True\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " )),\n",
       " EmptyState(),\n",
       " EmptyState())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.02830462],\n",
       "       [ 0.46713185],\n",
       "       [ 0.29570296]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = eqx.nn.Embedding(num_embeddings=9, embedding_size=3, key=rng)\n",
    "jnp.expand_dims(emb(0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = eqx.nn.MultiheadAttention(3, 15, 15, 15, 9, key=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key1, key2, key3 = jax.random.split(rng, 3)\n",
    "Q = jax.random.normal(key1, (100, 15))\n",
    "K = jax.random.normal(key2, (100, 15))\n",
    "V = jax.random.normal(key3, (100, 15))\n",
    "attention(Q, K, V).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "\n",
    "normalise_data = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "\n",
    "def collate(datapoint):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for d in datapoint:\n",
    "        images.append(d[\"image\"])\n",
    "        labels.append(d[\"label\"])\n",
    "\n",
    "    return (jnp.array(images) / jnp.array(images).max()) * 255, jnp.array(labels)\n",
    "\n",
    "\n",
    "dataset_train = load_dataset(\"mnist\", split=\"train\")\n",
    "# dataset_train.set_format(type=\"torch\")\n",
    "\n",
    "dataset_test = load_dataset(\"mnist\", split=\"test\")\n",
    "# dataset_test.set_format(type=\"torch\")\n",
    "train_loader = DataLoader(dataset_train, batch_size=2, collate_fn=collate)\n",
    "test_loader = DataLoader(dataset_test, batch_size=2, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(eqx.Module):\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "        # Standard CNN setup: convolutional layer, followed by flattening,\n",
    "        # with a small MLP on top.\n",
    "        self.layers = [\n",
    "            eqx.nn.Conv2d(1, 3, kernel_size=4, key=key1),\n",
    "            eqx.nn.MaxPool2d(kernel_size=2),\n",
    "            jax.nn.relu,\n",
    "            jnp.ravel,\n",
    "            eqx.nn.Linear(1728, 512, key=key2),\n",
    "            jax.nn.sigmoid,\n",
    "            eqx.nn.Linear(512, 64, key=key3),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Linear(64, 10, key=key4),\n",
    "            jax.nn.log_softmax,\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def cross_entropy(y, pred_y):\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy_loss(model: CNN, x, y):\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def l2_loss(model, x, y):\n",
    "    return jnp.linalg.norm(vmap(model)(x) - y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: shapes=[(2, 10), (2,)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:219\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_try_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrank_promoted_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbroadcast_shapes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    221\u001b[0m   \u001b[38;5;66;03m# Raise ValueError here for backward compatibility.\u001b[39;00m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:136\u001b[0m, in \u001b[0;36m_try_broadcast_shapes\u001b[0;34m(name, *shapes)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: broadcast_shapes got incompatible shapes for broadcasting: (2, 10), (1, 2).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/util.py:299\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrace_context_in_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_ignore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/util.py:293\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached\u001b[39m(_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 293\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:203\u001b[0m, in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;129m@cache\u001b[39m()\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_broadcast_shapes_cached\u001b[39m(\u001b[38;5;241m*\u001b[39mshapes: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m--> 203\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:222\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    221\u001b[0m   \u001b[38;5;66;03m# Raise ValueError here for backward compatibility.\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(2, 10), (2,)]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:136\u001b[0m, in \u001b[0;36m_try_broadcast_shapes\u001b[0;34m(name, *shapes)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: broadcast_shapes got incompatible shapes for broadcasting: (2, 10), (1, 2).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m key, subkey \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN(subkey)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.38\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.76\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/umbral/utils.py:120\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, testloader, optim, steps, print_every, loss_fn, evaluate_fn)\u001b[0m\n\u001b[1;32m    118\u001b[0m x \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    119\u001b[0m y \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m--> 120\u001b[0m model, opt_state, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m%\u001b[39m print_every) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (step \u001b[38;5;241m==\u001b[39m steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    122\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m evaluate_fn(model, testloader)\n",
      "    \u001b[0;31m[... skipping hidden 19 frame]\u001b[0m\n",
      "File \u001b[0;32m~/umbral/utils.py:103\u001b[0m, in \u001b[0;36mtrain.<locals>.make_step\u001b[0;34m(model, opt_state, x, y)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_step\u001b[39m(\n\u001b[1;32m     98\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     y: Int[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    102\u001b[0m ):\n\u001b[0;32m--> 103\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_value_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     updates, opt_state \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    105\u001b[0m         grads, opt_state, eqx\u001b[38;5;241m.\u001b[39mfilter(model, eqx\u001b[38;5;241m.\u001b[39mis_array)\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m     model \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(model, updates)\n",
      "    \u001b[0;31m[... skipping hidden 18 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[26], line 37\u001b[0m, in \u001b[0;36mnorm_loss\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnorm_loss\u001b[39m(model, x, y):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m)\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:1083\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1083\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:583\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    581\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 583\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/numpy/ufunc_api.py:182\u001b[0m, in \u001b[0;36mufunc.__call__\u001b[0;34m(self, out, where, *args)\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__static_props[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_vectorized\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/numpy/ufuncs.py:1568\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;129m@binary_ufunc\u001b[39m(identity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, at\u001b[38;5;241m=\u001b[39m_subtract_at)\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msubtract\u001b[39m(x: ArrayLike, y: ArrayLike, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Subtract two arrays element-wise.\u001b[39;00m\n\u001b[1;32m   1544\u001b[0m \n\u001b[1;32m   1545\u001b[0m \u001b[38;5;124;03m  JAX implementation of :obj:`numpy.subtract`. This is a universal function,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;124;03m    Array([-10,  -9,  -8,  -7], dtype=int32)\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1568\u001b[0m   out \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;241m*\u001b[39m\u001b[43mpromote_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubtract\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1569\u001b[0m   jnp_error\u001b[38;5;241m.\u001b[39m_set_error_if_nan(out)\n\u001b[1;32m   1570\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/numpy/util.py:228\u001b[0m, in \u001b[0;36mpromote_args\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m _check_no_float0s(fun_name, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    227\u001b[0m check_for_prngkeys(fun_name, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpromote_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpromote_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/numpy/util.py:64\u001b[0m, in \u001b[0;36mpromote_shapes\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mnumpy_rank_promotion\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     63\u001b[0m   _rank_promotion_warning_or_error(fun_name, shapes)\n\u001b[0;32m---> 64\u001b[0m result_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [lax\u001b[38;5;241m.\u001b[39mbroadcast_to_rank(arg, result_rank) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/umbral/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:222\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _try_broadcast_shapes(\u001b[38;5;241m*\u001b[39mrank_promoted_shapes, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    221\u001b[0m   \u001b[38;5;66;03m# Raise ValueError here for backward compatibility.\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(2, 10), (2,)]"
     ]
    }
   ],
   "source": [
    "from utils import train\n",
    "\n",
    "key, subkey = jax.random.split(rng, 2)\n",
    "model = CNN(subkey)\n",
    "\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    trainloader=train_loader,\n",
    "    testloader=test_loader,\n",
    "    optim=optim,\n",
    "    steps=200,\n",
    "    print_every=400,\n",
    "    loss_fn=l2_loss,\n",
    "    evaluate_fn=lambda x, y: (jnp.array([-1.38]), jnp.array([0.76])),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MultiHeadAttention, TransformerBlock\n",
    "import jax\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "attention = MultiHeadAttention(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jax.random.normal(rng, shape=(16, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = attention(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = TransformerBlock(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umbral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
